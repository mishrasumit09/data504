\documentclass[notes,11pt, aspectratio=169]{beamer}
\usepackage[default]{lato}


\input{lec_style.tex}


%----------------------------------------------------------------------------------------
  %	TITLE PAGE
%----------------------------------------------------------------------------------------
\title[DAR]{Data Analytics with R}  % The short title appears at the bottom of 
\author{Sumit Mishra} % Your name
\institute[IFMR] % Your institution as it will appear on the bottom of every slide, may be shorthand to save space
{
  Institute for Financial Management and Research, Sri City \\ % Your institution for the title page
  \medskip
  \medskip
  \textbf{Inference for Categorical Data} % Your email address
}
\date{05 December 2020} % Date, can be changed to a custom date

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
  % Begin document
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{document}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Title page
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

  
 {
    \addtocounter{framenumber}{-1} 
    {\removepagenumbers 
      %\usebackgroundtemplate{\includegraphics[width=\paperwidth]{../OpenIntro_Grid_4_3-01.jpg}}
      \begin{frame}
      
      %\hfill \includegraphics[width=20mm]{../oiLogo_highres}
      
      \titlepage
      
      \end{frame}
    }
  }

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Sections
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Inference for a single proportion}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}
\frametitle{Access to Toilet}

A survey asks the question about access to toilet. Below is the distribution of responses from a 2018 survey: \\

\begin{center}
\begin{tabular}{l c}
Households with toilet		& 320 \\
Households without toilet	& 350 \\
\hline
Total						& 670
\end{tabular}
\end{center}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}
\frametitle{Parameter and point estimate}

\dq{We would like to estimate the proportion of Indian households which have access to toilet? What are the parameter of interest and the point estimate?}

\pause

\begin{itemize}

\item \hl{Parameter of interest:} Proportion of \orange{all} Indian households who have access to toilet.
\[ \mathhl{p}~\scriptsize{(\text{a population proportion})} \]

\pause

\item \hl{Point estimate:} Proportion of \orange{sampled} Indians who have good intuition about experimental design.
\[ \mathhl{\hat{p}}~\scriptsize{(\text{a sample proportion})} \]

\end{itemize}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}
\frametitle{Inference on a proportion}

\dq{What percent of Indian households have access to toilet?}

\pause

\begin{itemize}

\item We can answer this question using a confidence interval, which we know is always of the form

\[ \textcolor{orange}{point~estimate \pm ME} \]

\pause

\item And we also know that \textcolor{orange}{$ME = critical~value \times standard~error$} of the point estimate.

\end{itemize}

\pause

\formula{Standard error of a sample proportion}
{
\[ SE_{\hat{p}} =  \sqrt{\frac{p~(1-p)}{n}}  \]
}


\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Identifying when a sample proportion is nearly normal}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}
\frametitle{Sample proportions are also nearly normally distributed}

\formula{Central limit theorem for proportions}
{
Sample proportions will be nearly normally distributed with mean equal to the population proportion, $p$, and standard error equal to $\sqrt{\frac{p~(1-p)}{n}}$.
\[ \hat{p} \sim N \pr{ mean = p, SE = \sqrt{\frac{p~(1-p)}{n}} } \]
}

But of course this is true only under certain conditions...

\dq{Any guesses?}

\soln{\pause{Independent observations, at least 10 successes and 10 failures}}

\pause

\Note{If $p$ is unknown (most cases), we use $\hat{p}$ in the calculation of the standard error.}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%\begin{frame}
%\frametitle{A quick activity}
%
%\pq{Flip a coin 20 times -- this is going to get loud! Record the number of heads and then use your clicker to submit the proportion of heads you obtained.}
%
%\begin{enumerate}[(a)]
%\item $\le$ 0.3
%\item 0.4
%\item 0.5
%\item 0.6
%\item $\ge$ 0.7
%\end{enumerate}
%
%\end{frame}
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%\begin{frame}
%
%\formula{Central limit theorem for proportions}
%{
%Sample proportions will be nearly normally distributed with mean equal to the population mean, $p$, and standard error equal to $\sqrt{\frac{p~(1-p)}{n}}$.
%\[ \hat{p} \sim N \pr{ mean = p, SE = \sqrt{\frac{p~(1-p)}{n}} } \]
%If the population proportion is not available, use the sample proportion to estimate the standard error.
%}
%
%\pause
%
%Assumptions/conditions:
%\begin{enumerate}[1.]
%\item \hl{Independence}: 
%\begin{itemize}
%\item \hlGr{Random sample}
%\item \hlGr{10\% condition}: If sampling without replacement, $n <$ 10\% of the population.
%\end{itemize}
%\item \hl{Normality}: At least 10 successes and 10 failures.
%\end{enumerate}
%
%\end{frame}
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Confidence intervals for a proportion}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}
\frametitle{Back to experimental design...}

\dq{The survey found that 320 out of 670 (48\%) households have access to toilet. Estimate (using a 95\% confidence interval) the proportion of all Indian households which have access to toilet?}

\pause
Given: $n = 670, \hat{p} = 0.48$. First, check conditions.

\pause
\begin{enumerate}[1.]
\item \hl{Independence}: The sample is random, and 670 $<$ 10\% of all Indian households, therefore we can assume that one respondent's response is independent of another.
\pause
\item \hl{Success-failure}: 320 households have access to toilet (successes) and 350 failures, both are greater than 10.
\end{enumerate}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}

\pq{We are given that  $n = 670, \hat{p} = 0.48$, we also just learned that the standard error of the sample proportion is $SE = \sqrt{\frac{p(1-p)}{n}}$. Which of the below is the correct calculation of the 95\% confidence interval?}

\begin{enumerate}[(a)]
\solnMult{$0.48 \pm 1.96 \times \sqrt{\frac{0.48 \times 0.52}{670}}$} \soln{\only<2>{\orange{$\rightarrow (0.44, 0.52)$}}}
\item $0.48 \pm 1.65 \times \sqrt{\frac{0.48 \times 0.52}{670}}$
\item $0.48 \pm 1.96 \times \frac{0.48 \times 0.52}{\sqrt{670}}$
\item $320 \pm 1.96 \times \sqrt{\frac{320 \times 350}{670}}$
\end{enumerate}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%\begin{frame}
%\frametitle{Interpretation of the CI}
%
%\pq{Based on this confidence interval, does it appear that more than a 80\% of Americans have a good intuition on experimental design? \\
%\soln{(0.82, 0.88)}
%}
%
%\begin{enumerate}[(a)]
%\solnMult{Yes}
%\item No
%\item Cannot tell
%\end{enumerate}
%
%\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Choosing a sample size when estimating a proportion}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}
\frametitle{Choosing a sample size}

\dq{How many households should you sample in order to cut the margin of error of a 95\% confidence interval down to 1\%.}
\pause
\[ ME = z^\star \times SE\]
\pause
\begin{eqnarray*}
0.01 &\ge& 1.96 \times \sqrt{\frac{0.48 \times 0.52}{n}} \orange{$\rightarrow$ \text{Use $\hat{p}$ from previous study}} \\
\pause
0.01^2 &\ge& 1.96^2 \times \frac{0.48 \times 0.52}{n} \\
\pause
n &\ge& \frac{1.96^2 \times 0.48 \times 0.52}{0.01^2} \\
\pause
n &\ge& 9584.7 \pause \orange{~$\rightarrow$ n \text{ should be at least 9585}}
\end{eqnarray*}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}
\frametitle{What if there isn't a previous study?}

... use $\hat{p} = 0.5$

\vspace{1cm}

\dq{why?}
\pause

\begin{itemize}
\item if you don't know any better, 50-50 is a good guess
\pause
\item $\hat{p} = 0.5$ gives the most conservative estimate -- highest possible sample size
\end{itemize}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Hypothesis testing for a proportion}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}
\frametitle{CI vs. HT for proportions}

\begin{itemize}

\item Success-failure condition:
\begin{itemize}
\item CI: At least 10 \orange{observed} successes and failures
\item HT: At least 10 \orange{expected} successes and failures, calculated using the null value
\end{itemize}

\item Standard error:
\begin{itemize}
\item CI: calculate using observed sample proportion: $SE = \sqrt{\frac{\hat{p}(1-\hat{p})}{n}}$
\item HT: calculate using the null value: $SE = \sqrt{\frac{p_0(1-p_0)}{n}}$
\end{itemize}

\end{itemize}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}
\frametitle{}

\dq{The survey found that 320 out of 670 (48\%) Indian households have access to toilet. Do these data provide convincing evidence that more than 40\% of Indians have access to toilet?}

\pause 

\[ H_0: p = 0.4 \qquad H_A: p > 0.4 \]

\twocol{0.6}{0.4}
{
\pause
\begin{eqnarray*}
SE &=& \sqrt{\frac{0.4 \times 0.6}{670}} = 0.019 \\
\pause
Z &=& \frac{0.48 - 0.4}{0.019} = 4.22 \\
\pause
p-value &=& 1 - 0.999982 \approx 0 \\
\end{eqnarray*}
}
\pause
Since the p-value is low, we reject $H_0$. The data provide convincing evidence that more than 40\% of Indian households have access to toilet.

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Recap}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}
\frametitle{}

\pq{11\% of 1,001 Americans responding to a 2006 Gallup survey stated that they have objections to celebrating Halloween on religious grounds. At 95\% confidence level, the margin of error for this survey is $\pm 3\%$. A news piece on this study's findings states: ``More than 10\% of all Americans have objections on religious grounds to celebrating Halloween." At 95\% confidence level, is this news piece's statement justified?}

\begin{enumerate}[(a)]
\item Yes
\solnMult{No}
\item Cannot tell
\end{enumerate}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}
\frametitle{Recap - inference for one proportion}

\begin{itemize}

\item Population parameter: $p$, point estimate: $\hat{p}$

\pause

\item Conditions:
\begin{itemize}
\item independence \\
- random sample and 10\% condition
\item at least 10 successes and failures\\ - if not $\rightarrow$ randomization
\end{itemize}

\pause

\item Standard error: $SE = \sqrt{ \frac{p(1-p)}{n} }$
\begin{itemize}
\item for CI: use $\hat{p}$
\item for HT: use $p_0$
\end{itemize}

\end{itemize}

\end{frame}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Difference of two proportions}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}
\frametitle{Results from a Survey}

A small pan-India survey asks a question about open defecation in India. Below are the distributions of responses from the survey as well as from a small survey conducted in villages in Tada: \\

\begin{center}
\begin{tabular}{l r r}
\hline
				& National Survey	& Village Survey \\
\hline
Frequently		& 454	& 69 \\
Sometimes			& 124 	& 30\\
A little			& 52 		& 4\\
Not at all			& 50 		& 2 \\
\hline
Total				& 680 	& 105\\
\hline
\end{tabular}
\end{center}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}
\frametitle{Parameter and point estimate}

\begin{itemize}

\item \hl{Parameter of interest:} Difference between the proportions of \orange{all} Tada residents and \orange{all} Indians who practice open defecation frequently.
\[ \mathhl{ p_{Tada} - p_{Ind} }\]

\pause

\item \hl{Point estimate:} Difference between the proportions of \orange{sampled} Tada residents and \orange{sampled} Indians who practice open defecation frequently.
\[ \mathhl{ \hat{p}_{Tada} - \hat{p}_{Ind} }\]

\end{itemize}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}
\frametitle{Inference for comparing proportions}

\begin{itemize}

\item The details are the same as before...

\pause

\item CI: \textcolor{orange}{$point~estimate \pm margin~of~error$}

\pause

\item HT: Use \textcolor{orange}{$Z = \frac{point~estimate - null~value}{SE}$} to find appropriate p-value.

\pause

\item We just need the appropriate standard error of the point estimate ($SE_{ \hat{p}_{Tada} - \hat{p}_{Ind}}$), which is the only new concept.

\end{itemize}

\pause

\formula{Standard error of the difference between two sample proportions}
{
\[ SE_{(\hat{p}_1 - \hat{p}_2)} = \sqrt{ \frac{p_1(1-p_1)}{n_1} + \frac{p_2(1-p_2)}{n_2} } \]
}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Confidence intervals for difference of proportions}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}
\frametitle{Conditions for CI for difference of proportions}

\begin{enumerate}

\item \hl{Independence within groups: }
\begin{itemize}
\item The pan-India group is sampled randomly and we're assuming that the Tada group represents a random sample as well.
\pause
\item 105 $<$ 10\% of all Tada residents and 680 $<$ 10\% of all Indians.
\end{itemize}
\pause
We can assume that the attitudes of people in Tada in the sample are independent of each other, and attitudes of all Indians in the sample are independent of each other as well.

\pause

\item \hl{Independence between groups: }
The sampled respondents from Tada and the Indian residents are independent of each other.

\pause

\item \hl{Success-failure:} \\
At least 10 observed successes and 10 observed failures in the two groups.

\end{enumerate}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}
\frametitle{}

\dq{Construct a 95\% confidence interval for the difference between the proportions of Tada respondents and Indians who practice open defecation frequently \orange{($p_{Tada} - p_{Ind}$)}.}

{\footnotesize
\begin{center}
\begin{tabular}{l | c c}
Data			& Tada		& India \\
\hline
Frequently	 & 69			& 454 \\
Not frequently  & 36			& 226 \\
\hline
Total	      & 105		& 680 \\
\hline
\pause
$\hat{p}$		& 0.657		& 0.668
\end{tabular}
\end{center}
}

\pause

\soln{
\begin{eqnarray*}
&& (\hat{p}_{Tada} - \hat{p}_{Ind}) \pm z^\star \times \sqrt{ \frac{ \hat{p}_{Tada} (1 - \hat{p}_{Tada})}{n_{Tada} } + \frac{ \hat{p}_{Ind} (1 -  \hat{p}_{Ind})}{n_{Ind} } }  \\
\pause
&=& (0.657 - 0.668) \pause \pm 1.96 \pause \times \sqrt{ \frac{0.657 \times 0.343}{105} + \frac{0.668 \times 0.332}{680} } \\
\pause
&=& -0.011 \pm \pause 1.96 \times 0.0497 \\
\pause
&=& -0.011 \pm 0.097 \\
\pause
&=& (-0.108, 0.086)
\end{eqnarray*}
}


\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{HT for comparing proportions}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}

\pq{Which of the following is the correct set of hypotheses for testing if the proportion of all Tada residents who practice open defecation frequently differs from the proportion of all Indians who do?}

\begin{enumerate}[(a)]
\solnMult{ $H_0:  p_{Tada} = p_{Ind}$ \\
$H_A:  p_{Tada} \ne p_{Ind}$ }
\item $H_0:  \hat{p}_{Tada} = \hat{p}_{Ind}$ \\
$H_A:  \hat{p}_{Tada} \ne \hat{p}_{Ind}$
\solnMult{ $H_0:  p_{Tada} - p_{Ind} = 0$ \\
$H_A:  p_{Tada} - p_{Ind} \ne 0$ }
\item $H_0:  p_{Tada} = p_{Ind}$ \\
$H_A:  p_{Tada} < p_{Ind}$
\end{enumerate}

\soln{
\only<2>{\orange{Both (a) and (c) are correct.}}
}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}
\frametitle{Flashback to working with one proportion}

\begin{itemize}

\item When constructing a confidence interval for a population proportion, we check if the \orange{observed} number of successes and failures are at least 10.
\[ n\hat{p} \ge 10 \qquad \qquad n(1-\hat{p}) \ge 10 \]

\pause

\item When conducting a hypothesis test for a population proportion, we check if the \orange{expected} number of successes and failures are at least 10.
\[ np_0 \ge 10 \qquad \qquad n(1-p_0) \ge 10 \]

\end{itemize}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}
\frametitle{Pooled estimate of a proportion}

\begin{itemize}

\item In the case of comparing two proportions where $H_0: p_1 = p_2$, there isn't a given null value we can use to calculated the \orange{expected} number of successes and failures in each sample.

\pause

\item Therefore, we need to first find a common (\hl{pooled}) proportion for the two groups, and use that in our analysis.

\pause

\item This simply means finding the proportion of total successes among the total number of observations.

\end{itemize}

$\:$ \\

\formula{Pooled estimate of a proportion}
{ \[ \hat{p} = \frac{\#~of~successes_1 + \#~of~successes_2}{n_1 + n_2} \] }

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}
\frametitle{}

\dq{Calculate the estimated \underline{pooled proportion} of Tada residents and Indians who practice open defecation. Which sample proportion ($\hat{p}_{Tada}$ or $\hat{p}_{Ind}$) the pooled estimate is closer to? Why?}

{\footnotesize
\begin{center}
\begin{tabular}{l | c c}
Data			& Tada		& India \\
\hline
Frequently	& 69			& 454 \\
Not frequently     & 36			& 226 \\
\hline
Total			& 105		& 680 \\
\hline
$\hat{p}$		& 0.657		& 0.668
\end{tabular}
\end{center}
}

\pause

\soln{
\begin{eqnarray*}
\hat{p} &=& \frac{\#~of~successes_1 + \#~of~successes_2}{n_1 + n_2} \\
\pause
&=& \frac{69+454}{105+680} \pause = \frac{523}{785} \pause = 0.666
\end{eqnarray*}
}

\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}
\frametitle{}

\dq{Do these data suggest that the proportion of all Tada residents who practice open defecation differs from the proportion of all Indians who do? Calculate the test statistic, the p-value, and interpret your conclusion in context of the data.}

{\footnotesize
\begin{center}
\begin{tabular}{l | c c}
Data			& Tada		& India \\
\hline
Frequently	& 69			& 454 \\
Not frequently & 36			& 226 \\
\hline
Total			& 105		& 680 \\
\hline
$\hat{p}$		& 0.657		& 0.668
\end{tabular}
\end{center}
}

\pause

\soln{
\begin{eqnarray*}
Z &=& \frac{(\hat{p}_{Tada} - \hat{p}_{Ind})}{\sqrt{ \frac{ \hat{p} (1 - \hat{p})}{n_{Tada} } + \frac{ \hat{p} (1 -  \hat{p})}{n_{Ind} } }} \\
\pause 
&=& \frac{(0.657 - 0.668)}{\sqrt{ \frac{0.666 \times 0.334}{105} + \frac{0.666 \times 0.334}{680} }} = \pause \frac{-0.011}{0.0495} \pause = -0.22 \\
\pause
p-value &=& 2 \times P(Z < -0.22) \pause = 2 \times 0.41 = 0.82
\end{eqnarray*}
}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Recap}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}
\frametitle{Recap - comparing two proportions}

\begin{itemize}

\item Population parameter: $(p_1 - p_2)$, point estimate: $(\hat{p}_1 - \hat{p}_2)$

\pause

\item Conditions:
\pause
\begin{itemize}
\item independence within groups \\
- random sample and 10\% condition met for both groups
\item independence between groups
\item at least 10 successes and failures in each group\\ 
- if not $\rightarrow$ randomization (Section 6.4)
\end{itemize}

\pause

\item $SE_{(\hat{p}_1 - \hat{p}_2)} = \sqrt{ \frac{p_1(1-p_1)}{n_1} + \frac{p_2(1-p_2)}{n_2} }$
\begin{itemize}
\item for CI: use $\hat{p}_1$ and $\hat{p}_2$
\item for HT:
\begin{itemize}
\item when $H_0: p_1 = p_2$: use $\hat{p}_{pool} = \frac{\#~suc_1 + \#suc_2}{n_1 + n_2}$
\item when $H_0: p_1 - p_2 = $ \textit{(some value other than 0)}: use $\hat{p}_1$ and $\hat{p}_2$ \\
- this is pretty rare
\end{itemize}
\end{itemize}

\end{itemize}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}
\frametitle{Reference - standard error calculations}

\begin{center}
\begin{tabular}{l | l | l}
			& one sample					& two samples \\ 
\hline
& & \\
mean		& $SE = \frac{s}{\sqrt{n}}$			& $SE = \sqrt{ \frac{s_1^2}{n_1} + \frac{s_2^2}{n_2}}$ \\
& & \\
\hline
& & \\
proportion		& $SE = \sqrt{ \frac{p(1-p)}{n} }$	& $SE = \sqrt{ \frac{p_1(1-p_1)}{n_1} + \frac{p_2(1-p_2)}{n_2} }$	 \\	
& & \\
\end{tabular}
\end{center}

\pause

\begin{itemize}

\item When working with means, it's very rare that $\sigma$ is known, so we usually use $s$.

\pause

\item When working with proportions, 
\begin{itemize}
\item if doing a hypothesis test, $p$ comes from the null hypothesis
\item if constructing a confidence interval, use $\hat{p}$ instead
\end{itemize}

\end{itemize}

\end{frame}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Chi-square test of GOF}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Weldon's dice}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}
\frametitle{Weldon's dice}

\twocol{0.75}{0.25}
{
\begin{itemize}

\item Walter Frank Raphael Weldon (1860 - 1906), was an English evolutionary biologist and a founder of biometry. He was the joint founding editor of Biometrika, with Francis Galton and Karl Pearson.

\item In 1894, he rolled 12 dice 26,306 times, and recorded the number of 5s or 6s (which he considered to be a success).

\end{itemize}
}
{
\begin{center}
\includegraphics[width=\textwidth]{graphs/weldon}
\end{center}
}
\begin{itemize}

\item It was observed that 5s or 6s occurred more often than expected, and Pearson hypothesized that this was probably due to the construction of the dice. Most inexpensive dice have hollowed-out pips, and since opposite sides add to 7, the face with 6 pips is lighter than its opposing face, which has only 1 pip.

\end{itemize}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}
\frametitle{Labby's dice}

\twocol{0.6}{0.4}
{
\begin{itemize}

\item In 2009, Zacariah Labby (U of Chicago), repeated Weldon's experiment using a homemade dice-throwing, pip counting machine.
\begin{center}
\webURL{http://www.youtube.com/watch?v=95EErdouO2w}
\end{center}

\item The rolling-imaging process took about 20 seconds per roll.

\end{itemize}
}
{
\begin{center}
\includegraphics[width=\textwidth]{graphs/labby}
\end{center}
}

\begin{itemize}

\item Each day there were $\sim$150 images to process manually.

\item At this rate Weldon's experiment was repeated in a little more than six full days.

\item Recommended reading: \webURL{http://galton.uchicago.edu/about/docs/labby09dice.pdf}

\end{itemize}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}
\frametitle{Labby's dice (cont.)}

\begin{itemize}

\item Labby did not actually observe the same phenomenon that Weldon observed (higher frequency of 5s and 6s).

\item Automation allowed Labby to collect more data than Weldon did in 1894, instead of recording ``successes" and ``failures", Labby recorded the individual number of pips on each die.

\end{itemize}

\begin{center}
\includegraphics[width=0.3\textwidth]{graphs/labbyPipCounts}
\end{center}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection*{Creating a test statistic for one-way tables}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}
\frametitle{Expected counts}

\pq{Labby rolled 12 dice 26,306 times. If each side is equally likely to come up, how many 1s, 2s, $\cdots$, 6s would he expect to have observed?}

\begin{enumerate}[(a)]
\item $\frac{1}{6}$
\item $\frac{12}{6}$
\item $\frac{26,306}{6}$
\solnMult{ $\frac{12 \times 26,306}{6}$ } \soln{\only<2>{\orange{$= 52,612$}}}
\end{enumerate}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}
\frametitle{Summarizing Labby's results}

The table below shows the observed and expected counts from Labby's experiment.

{\small
\begin{center}
\renewcommand\arraystretch{1.2}
\begin{tabular}{c | c c}
Outcome	& Observed	& Expected \\
\hline
1		& 53,222		& 52,612 \\
2		& 52,118		& 52,612 \\
3		& 52,465		& 52,612 \\
4		& 52,338		& 52,612 \\
5		& 52,244		& 52,612 \\
6		& 53,285		& 52,612 \\
\hline
Total		& 315,672		& 315,672
\end{tabular}
\end{center}
}

\pause
\dq{Why are the expected counts the same for all outcomes but the observed counts are different? At a first glance, does there appear to be an inconsistency between the observed and expected counts?}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}
\frametitle{Setting the hypotheses}

\dq{Do these data provide convincing evidence of an inconsistency between the observed and expected counts?}

\pause

\begin{itemize}
\item[$H_0$:] There is no inconsistency between the observed and the expected counts. \hlGr{The observed counts follow the same distribution as the expected counts.}

\pause

\item[$H_A$:] There is an inconsistency between the observed and the expected counts. \hlGr{The observed counts \orange{do not} follow the same distribution as the expected counts.} There is a bias in which side comes up on the roll of a die.
\end{itemize}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}
\frametitle{Evaluating the hypotheses}

\begin{itemize}

\item To evaluate these hypotheses, we quantify how different the observed counts are from the expected counts. 

\pause

\item Large deviations from what would be expected based on sampling variation (chance) alone provide strong evidence for the alternative hypothesis.

\pause

\item This is called a \hl{goodness of fit} test since we're evaluating how well the observed data fit the expected distribution.

\end{itemize}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{The chi-square test statistic}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}
\frametitle{Anatomy of a test statistic}

\begin{itemize}

\item The general form of a test statistic is
\[ \frac{\text{point estimate} - \text{null value}}{\text{SE of point estimate}} \]

\pause

\item This construction is based on 
\begin{enumerate}
\item identifying the difference between a point estimate and an expected value if the null hypothesis was true, and 
\item standardizing that difference using the standard error of the point estimate. 
\end{enumerate}
\pause

These two ideas will help in the construction of an appropriate test statistic for count data.

\end{itemize}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}
\frametitle{Chi-square statistic}

When dealing with counts and investigating how far the observed counts are from the expected counts, we use a new test statistic called the \hl{chi-square ($\chi^2$) statistic}.

$\:$ \\

\pause

\formula{$\chi^2$ statistic}
{
\[\chi^2 = \sum_{i = 1}^k \frac{(O - E)^2}{E} \qquad \text{where $k$ = total number of cells} \]
}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}
\frametitle{Calculating the chi-square statistic}

\begin{center}
\renewcommand\arraystretch{1.8}
\begin{tabular}{c | c c | c}
Outcome	& Observed	& Expected 	& $\frac{(O - E)^2}{E}$\\
\hline
1		& 53,222		& 52,612 		& $\frac{(53,222 - 52,612)^2}{52,612} = 7.07$ \\
\pause
2		& 52,118		& 52,612 		& $\frac{(52,118 - 52,612)^2}{52,612} = 4.64$ \\
\pause
3		& 52,465		& 52,612 		& $\frac{(52,465 - 52,612)^2}{52,612} = 0.41$ \\
\pause
4		& 52,338		& 52,612 		& $\frac{(52,338 - 52,612)^2}{52,612} = 1.43$\\
\pause
5		& 52,244		& 52,612 		& $\frac{(52,244 - 52,612)^2}{52,612} = 2.57$\\
\pause
6		& 53,285		& 52,612 		& $\frac{(53,285 - 52,612)^2}{52,612} = 8.61$\ \\
\hline
\pause
Total		& 315,672		& 315,672		& 24.73
\end{tabular}
\end{center}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}
\frametitle{Why square?}


Squaring the difference between the observed and the expected outcome does two things:
\pause
\begin{itemize}
\item Any standardized difference that is squared will now be positive.
\pause
\item Differences that already looked unusual will become much larger after being squared.
\end{itemize}

\vspace{1cm}

\pause
\dq{When have we seen this before?}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{The chi-square distribution and finding areas}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}
\frametitle{The chi-square distribution}

\begin{itemize}

\item In order to determine if the $\chi^2$ statistic we calculated is considered unusually high or not we need to first describe its distribution.

\pause

\item The chi-square distribution has just one parameter called \hl{degrees of freedom (df)}, which influences the shape, center, and spread of the distribution. \\

\end{itemize}

\pause

$\:$ \\

\Remember{So far we've seen three other continuous distributions:
\begin{itemize}
\item[-] normal distribution: unimodal and symmetric with two parameters: mean and standard deviation
\item[-] T distribution: unimodal and symmetric with one parameter: degrees of freedom
\item[-] F distribution: unimodal and right skewed with two parameters: degrees of freedom or numerator (between group variance) and denominator (within group variance)
\end{itemize}
}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}
\frametitle{}

\pq{Which of the following is false?}

\begin{center}
\includegraphics[width=0.7\textwidth]{graphs/chiSquareDistributionWithInceasingDF}
\end{center}

As the df increases,
\begin{enumerate}[(a)]
\item the center of the $\chi^2$ distribution increases as well
\item the variability of the $\chi^2$ distribution increases as well
\solnMult{the shape of the $\chi^2$ distribution becomes more skewed (less like a normal)}
\end{enumerate}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}[fragile]
\frametitle{Finding areas under the chi-square curve}

\begin{itemize}

\item p-value = tail area under the chi-square distribution (as usual)

\pause

\item For this we can use technology,or a chi-square probability table.

\end{itemize}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}[fragile]
\frametitle{Finding areas under the chi-square curve (cont.)}

\dq{Estimate the shaded area (above the cutoff value of 10) under the $\chi^2$ curve with $df = 6$.}

\pause

\begin{verbatim}

> pchisq(q = 10, df = 6, lower.tail = FALSE)

[1] 0.124652

\end{verbatim}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}[fragile]
\frametitle{Finding areas under the chi-square curve (cont.)}

\pq{Estimate the shaded area (above the cutoff value of 17) under the $\chi^2$ curve with $df = 9$.}

\twocol{0.6}{0.4}{
\begin{center}
\includegraphics[width=0.67\textwidth]{graphs/above17WithDF9}
\end{center}
}
{
{\small
\begin{enumerate}[(a)]
\setlength{\itemsep}{0in}
\item 0.05
\item 0.02
\solnMult{between 0.02 and 0.05}
\item between 0.05 and 0.1
\item between 0.01 and 0.02
\end{enumerate}
}
}

\pause

\begin{verbatim}

> pchisq(q = 17, df = 9, lower.tail = FALSE)

[1] 0.04871598

\end{verbatim}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}[fragile]
\frametitle{Finding areas under the chi-square curve (one more)}

\pq{Estimate the shaded area (above 30) under the $\chi^2$ curve with $df = 10$.}

\twocol{0.6}{0.4}{
\begin{center}
\includegraphics[width=0.67\textwidth]{graphs/above30WithDF10}
\end{center}
}
{
{\small
\begin{enumerate}[(a)]
\setlength{\itemsep}{0in}
\item greater than 0.3
\item between 0.005 and 0.001
\solnMult{less than 0.001}
\item greater than 0.001
\item cannot tell using this table
\end{enumerate}
}
}

\pause

\begin{verbatim}

> pchisq(q = 30, df = 10, lower.tail = FALSE)

[1] 0.0008566412

\end{verbatim}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Finding a p-value for a chi-square test}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}
\frametitle{Back to Labby's dice}

\begin{itemize}

\item The research question was: Do these data provide convincing evidence of an inconsistency between the observed and expected counts?

\pause

\item The hypotheses were:
\begin{itemize}
\item[$H_0$:] There is no inconsistency between the observed and the expected counts. The observed counts follow the same distribution as the expected counts.
\item[$H_A$:] There is an inconsistency between the observed and the expected counts. The observed counts \orange{do not} follow the same distribution as the expected counts. There is a bias in which side comes up on the roll of a die.
\end{itemize}

\pause

\item We had calculated a test statistic of \orange{$\chi^2 = 24.67$}.

\pause

\item All we need is the $df$ and we can calculate the tail area (the p-value) and make a decision on the hypotheses.

\end{itemize}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}
\frametitle{Degrees of freedom for a goodness of fit test}

\begin{itemize}

\item When conducting a goodness of fit test to evaluate how well the observed data follow an expected distribution, the degrees of freedom are calculated as the number of cells ($k$) minus 1.
\[ \mathhl{df = k - 1} \]

\pause

\item For dice outcomes, $k = 6$, therefore
\[ df = 6 - 1 = 5 \]

\end{itemize}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}
\frametitle{Finding a p-value for a chi-square test}

The \hl{p-value} for a chi-square test is defined as the \hl{tail area above the calculated test statistic}.

\twocol{0.6}{0.4}{
\begin{center}
\includegraphics[width=0.67\textwidth]{graphs/above24Point67WithDF5}
\end{center}
}
{
p-value = $P(\chi^2_{df = 5} > 24.67)$\\ is less than 0.001
}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}
\frametitle{Conclusion of the hypothesis test}

\pq{We calculated a p-value less than 0.001. At 5\% significance level, what is the conclusion of the hypothesis test?}

\begin{enumerate}[(a)]
\item Reject $H_0$, the data provide convincing evidence that the dice are fair.
\solnMult{Reject $H_0$, the data provide convincing evidence that the dice are biased.}
\item Fail to reject $H_0$, the data provide convincing evidence that the dice are fair.
\item Fail to reject $H_0$, the data provide convincing evidence that the dice are biased.
\end{enumerate}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}
\frametitle{Turns out...}

\begin{itemize}

\item The 1-6 axis is consistently shorter than the other two (2-5 and 3-4), thereby supporting the hypothesis that the faces with one and six pips are larger than the other faces.

\item Pearson's claim that 5s and 6s appear more often due to the carved-out pips is not supported by these data.

\item Dice used in casinos have flush faces, where the pips are filled in with a plastic of the same density as the surrounding material and are precisely balanced.

\end{itemize}

\begin{center}
\includegraphics[width=0.3\textwidth]{graphs/regular}
\includegraphics[width=0.3\textwidth]{graphs/casino}
\end{center}


\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}
\frametitle{Recap: p-value for a chi-square test}

\begin{itemize}

\item The p-value for a chi-square test is defined as the tail area \hl{above} the calculated test statistic.

\item This is because the test statistic is always positive, and a higher test statistic means a stronger deviation from the null hypothesis.

\end{itemize}

\begin{center}
\includegraphics[width=0.7\textwidth]{graphs/genericChiSquare}
\end{center}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}
\frametitle{Conditions for the chi-square test}

\begin{enumerate}

\item \hlGr{Independence:} Each case that contributes a count to the table must be independent of all the other cases in the table.

\pause

\item \hlGr{Sample size:} Each particular scenario (i.e. cell) must have at least 5 \orange{expected} cases.

\pause

\item \hlGr{df $>$ 1:} Degrees of freedom must be greater than 1.

\end{enumerate}

\pause

Failing to check conditions may unintentionally affect the test's error rates.

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{2009 Iran Election}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}
\frametitle{2009 Iran Election}

\dq{There was lots of talk of election fraud in the 2009 Iran election. We'll compare the data from a poll conducted before the election (observed data) to the reported votes in the election to see if the two follow the same distribution.}

\begin{center}
\begin{tabular}{l | r r}
					& \footnotesize{Observed \# of} & \footnotesize{Reported \% of} \\
\footnotesize{Candidate}	& \footnotesize{voters in poll} & \footnotesize{votes in election} \\
\hline
(1) Ahmedinajad	& 338	& 63.29\% \\
(2) Mousavi		& 136	& 34.10\% \\
(3) Minor candidates	& 30	& 2.61\% \\
\hline
Total			& 504	& 100\% \\
\pause
			& \hl{$\downarrow$}	& \hl{$\downarrow$}	\\
			& \hl{observed}	& \hl{expected} \\
			& 			& \hl{distribution} 	
\end{tabular}
\end{center}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}
\frametitle{Hypotheses}

\dq{What are the hypotheses for testing if the distributions of reported and polled votes are different?}

\soln{
\only<2>{
\begin{itemize}
\item[$H_0$:] The observed counts from the poll follow the same distribution as the reported votes.
\item[$H_A$:] The observed counts from the poll do not follow the same distribution as the reported votes.
\end{itemize}
}}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}
\frametitle{Calculation of the test statistic}

{\small
\begin{center}
\begin{tabular}{l | r r r}
					& \footnotesize{Observed \# of} & \footnotesize{Reported \% of}	& \footnotesize{Expected \# of} \\
\footnotesize{Candidate}	& \footnotesize{voters in poll} & \footnotesize{votes in election}		&  \footnotesize{votes in poll} \\
\hline
\footnotesize{(1) Ahmedinajad}	& 338	& 63.29\% 	& 504 $\times$ 0.6329 = 319 \\
\footnotesize{(2) Mousavi}		& 136	& 34.10\%		& 504 $\times$ 0.3410 = 172 \\
\footnotesize{(3) Minor candidates}	& 30	& 2.61\% 		& 504 $\times$ 0.0261 = 13\\
\hline
Total			& 504	& 100\%		& 504
\end{tabular}
\end{center}
}

\pause

\begin{eqnarray*}
\frac{(O_1 - E_1)^2}{E_1} = \frac{(338 - 319)^2}{319} &=& 1.13 \\
\pause
\frac{(O_2 - E_2)^2}{E_2} = \frac{(136 - 172)^2}{172} &=& 7.53 \\
\pause
\frac{(O_2 - E_2)^2}{E_2} = \frac{(30 - 13)^2}{13} &=& 22.23 \\
\pause
 \chi^2_{\mathhl{df = 3 - 1 = 2}} &=& 30.89
\end{eqnarray*}


\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}
\frametitle{Conclusion}

\pq{Based on these calculations what is the conclusion of the hypothesis test?}

\begin{enumerate}[(a)]
\solnMult{p-value is low, $H_0$ is rejected. The observed counts from the poll do \underline{not} follow the same distribution as the reported votes.}
\item p-value is high, $H_0$ is not rejected. The observed counts from the poll follow the same distribution as the reported votes.
\item p-value is low, $H_0$ is rejected. The observed counts from the poll follow the same distribution as the reported votes
\item p-value is low, $H_0$ is not rejected. The observed counts from the poll do \underline{not} follow the same distribution as the reported votes.
\end{enumerate}

\end{frame}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Chi-square test of independence}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Popular kids}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}
\frametitle{Popular kids}

\dq{In the dataset \texttt{popular}, students in grades 4-6 were asked whether good grades, athletic ability, or popularity was most important to them. A two-way table separating the students by grade and by choice of most important factor is shown below. Do these data provide evidence to suggest that goals vary by grade?}

\twocol{0.5}{0.5}
{
\begin{center}
\begin{tabular}{rrrr}
  \hline
 & Grades & Popular & Sports \\ 
  \hline
$4^{th}$ &  63 &  31 &  25 \\ 
$5^{th}$ &  88 &  55 &  33 \\ 
$6^{th}$ &  96 &  55 &  32 \\ 
   \hline
\end{tabular}
\end{center}
}
{
\begin{center}
\includegraphics[width=0.5\textwidth]{graphs/popular_mosaic}
\end{center}
}


\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}
\frametitle{Chi-square test of independence}

\begin{itemize}
\item The hypotheses are:
\begin{itemize}
\item[$H_0$:] Grade and goals are independent. Goals do not vary by grade.
\item[$H_A$:] Grade and goals are dependent. Goals vary by grade.
\end{itemize}

\pause

\item The test statistic is calculated as
\[ \chi^2_{df} = \sum_{i = 1}^{k} \frac{(O - E)^2}{E} \quad \text{ where } \quad df = (R - 1) \times (C - 1), \]
where $k$ is the number of cells, $R$ is the number of rows, and $C$ is the number of columns.

\Note{We calculate $df$ differently for one-way and two-way tables.}

\pause

\item The p-value is the area under the $\chi^2_{df}$ curve, above the calculated test statistic.

\end{itemize}


\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Expected counts in two-way tables}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}
\frametitle{Expected counts in two-way tables}

\formula{Expected counts in two-way tables}
{
\[ \text{Expected Count} = \frac{(\text{row total}) \times (\text{column total})}{\text{table total}} \]
}

\pause

{\small
\begin{center}
\begin{tabular}{rrrr|r}
  \hline
 & Grades & Popular & Sports	& Total \\ 
  \hline
$4^{th}$ &  \orange{63} &  \green{31} &  25 	&119 \\ 
$5^{th}$ &  88 &  55 &  33	& 176 \\ 
$6^{th}$&  96 &  55 &  32	& 183 \\ 
   \hline
Total	& 247	& 141	& 90	& 478 \\
\end{tabular}
\end{center}
}

\pause

\[ \orange{$E_{row~1, col~1} = \frac{119 \times 247}{478} = 61$} \qquad \pause
 \green{$E_{row~1, col~2} = \frac{119 \times 141}{478} = 35$} \]

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}
\frametitle{Expected counts in two-way tables}

\pq{What is the expected count for the highlighted cell?}

{\small
\begin{center}
\begin{tabular}{rrrr|r}
  \hline
 & Grades & Popular & Sports	& Total \\ 
  \hline
$4^{th}$ &  63 &  31 &  25 	&119 \\ 
$5^{th}$ &  88 &  \orange{55} &  33	& 176 \\ 
$6^{th}$ &  96 &  55 &  32	& 183 \\ 
   \hline
Total	& 247	& 141	& 90	& 478 \\
\end{tabular}
\end{center}
}

\twocol{0.2}{0.8}
{
\begin{enumerate}[(a)]
\solnMult{$\frac{176 \times 141}{478}$}
\item $\frac{119 \times 141}{478}$
\item $\frac{176 \times 247}{478}$
\item $\frac{176 \times 478}{478}$
\end{enumerate}
}
{
\soln{\only<2>{
\orange{$\rightarrow$ 52\\
{\small more than expected \# of 5th graders \\
have a goal of being popular}}
\vspace{0.75cm}
}
}
}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}
\frametitle{Calculating the test statistic in two-way tables}

Expected counts are shown in \ex{blue} next to the observed counts.
\begin{center}
\begin{tabular}{rrrr|r}
  \hline
 & Grades & Popular & Sports	& Total \\ 
  \hline
$4^{th}$ 	&  63 \ex{61} &  31 \ex{35} &  25 \ex{23}	&119 \\ 
$5^{th}$ 	&  88 \ex{91} &  55 \ex{52} &  33 \ex{33}	& 176 \\ 
$6^{th}$	&  96 \ex{95} &  55 \ex{54} &  32 \ex{34}	& 183 \\ 
   \hline
Total	& 247	& 141	& 90	& 478 \\
\end{tabular}
\end{center}

\vspace{0.5cm}

\pause

\begin{eqnarray*} 
\chi^2 &=& \sum \frac{(63 - 61)^2}{61} + \frac{(31 - 35)^2}{35} + \cdots + \frac{(32 - 34)^2}{34} = 1.3121 \\
\pause
df &=& (R - 1) \times (C - 1) = (3 - 1) \times (3 - 1) = 2 \times 2 = 4 
\end{eqnarray*}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Results}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}
\frametitle{Calculating the p-value}

\pq{Which of the following is the correct p-value for this hypothesis test?
\[ \chi^2 = 1.3121 \qquad df = 4 \]
}

\twocol{0.6}{0.4}{
\begin{center}
\includegraphics[width=0.5\textwidth]{graphs/popular}
\end{center}
}
{
{\small
\begin{enumerate}[(a)]
\setlength{\itemsep}{0in}
\solnMult{ more than 0.3}
\item between 0.3 and 0.2
\item between 0.2 and 0.1
\item between 0.1 and 0.05
\item less than 0.001
\end{enumerate}
}
}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}
\frametitle{Conclusion}

\dq{Do these data provide evidence to suggest that goals vary by grade?}

\begin{itemize}

\item[$H_0$:] Grade and goals are independent. Goals do not vary by grade.

\item[$H_A$:] Grade and goals are dependent. Goals vary by grade. \\

\end{itemize}

$\:$ \\

\soln{\only<2>{Since p-value is high, we fail to reject $H_0$. The data do not provide convincing evidence that grade and goals are dependent. It doesn't appear that goals vary by grade.
}
}

\end{frame}



\end{document}